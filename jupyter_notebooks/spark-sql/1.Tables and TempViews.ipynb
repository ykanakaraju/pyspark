{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"./Setup.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputPath = \"E:\\\\PySpark\\\\data\\\\users.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = spark.read.json(inputPath)\n",
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.createOrReplaceTempView(\"users\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.catalog.listTables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qry = \"\"\"select age, count(1) as count\n",
    "        from users\n",
    "        where age is not null\n",
    "        group by age\n",
    "        order by count\n",
    "        limit 5\"\"\"\n",
    "\n",
    "df2 = spark.sql(qry)\n",
    "\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GlobalTempViews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.createOrReplaceGlobalTempView(\"gusers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.catalog.listTables(\"global_temp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.catalog.currentDatabase()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qry2 = \"\"\"select age, count(1) as count\n",
    "        from global_temp.gusers\n",
    "        where age is not null\n",
    "        group by age\n",
    "        order by count\n",
    "        limit 5\"\"\"\n",
    "\n",
    "df3 = spark.sql(qry2)\n",
    "\n",
    "df3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark2 = spark.newSession()\n",
    "\n",
    "qry2 = \"\"\"select age, count(1) as count\n",
    "        from global_temp.gusers\n",
    "        where age is not null\n",
    "        group by age\n",
    "        order by count\n",
    "        limit 5\"\"\"\n",
    "\n",
    "df3 = spark2.sql(qry2)\n",
    "\n",
    "df3.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a new session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark2 = spark.newSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.catalog.listTables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "spark2.catalog.listTables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qry = \"\"\"select age, count(1) as count\n",
    "        from users\n",
    "        where age is not null\n",
    "        group by age\n",
    "        order by count\n",
    "        limit 5\"\"\"\n",
    "\n",
    "df2 = spark2.sql(qry)\n",
    "\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(qry2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = spark2.sql(qry2)\n",
    "\n",
    "df3.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving to tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.get(\"spark.sql.warehouse.dir\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spark.conf.set(\"spark.sql.warehouse.dir\", \"E:\\\\PySpark\\\\Warehouse\\\\spark-warehouse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.catalog.currentDatabase()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"desc database default\").show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df1.where(\"age is not null and gender = 'Male'\")\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.write.format(\"json\").saveAsTable(\"users_json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.catalog.listTables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"select * from users_json where age > 20\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.write.format(\"csv\").option(\"header\", True).saveAsTable(\"users_csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age = 20\n",
    "spark.sql(f\"select * from users_csv where age > {age}\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### External Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 \\\n",
    ".write \\\n",
    ".format(\"parquet\") \\\n",
    ".option(\"path\", \"E:\\\\PySpark\\\\external\\\\users_parquet\") \\\n",
    ".saveAsTable(\"users_parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.catalog.listTables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age = 20\n",
    "spark.sql(f\"select * from users_parquet where age > {age}\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df1.where(\"age is not null and gender = 'Female'\")\n",
    "df3.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Appending data to an existing table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 \\\n",
    ".write \\\n",
    ".format(\"json\") \\\n",
    ".mode(\"append\") \\\n",
    ".saveAsTable(\"users_json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"select * from users_json\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropping managed and external tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.catalog.listTables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"drop table default.users_csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++\n",
      "||\n",
      "++\n",
      "++\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"drop table default.users_json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"drop table default.users_parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a schema/database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"create database demodb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+----------------------------------------------------------------------------------+\n",
      "|database_description_item|database_description_value                                                        |\n",
      "+-------------------------+----------------------------------------------------------------------------------+\n",
      "|Database Name            |demodb                                                                            |\n",
      "|Description              |                                                                                  |\n",
      "|Location                 |file:/E:/PySpark/jupyter-notebooks/july-2025-3/spark-sql/spark-warehouse/demodb.db|\n",
      "|Owner Name               |                                                                                  |\n",
      "|Owner Type               |                                                                                  |\n",
      "+-------------------------+----------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"describe database demodb\").show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"use demodb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'demodb'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.catalog.currentDatabase()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.write.format(\"csv\").option(\"header\", True).saveAsTable(\"users_csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Table(name='users_csv', database='demodb', description=None, tableType='MANAGED', isTemporary=False),\n",
       " Table(name='users_json', database='demodb', description=None, tableType='MANAGED', isTemporary=False)]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.catalog.listTables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.write.format(\"json\").saveAsTable(\"users_json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+-------+----------+------+\n",
      "|age|gender|   name|     phone|userid|\n",
      "+---+------+-------+----------+------+\n",
      "| 25|  Male|  Satya|8501099876|     1|\n",
      "| 25|  Male|  Rahim|      null|     3|\n",
      "| 13|  Male| Sundar|8522233456|     6|\n",
      "| 28|  Male|  Steve|8501085009|     7|\n",
      "| 13|  Male| Samuel|8522235624|    11|\n",
      "| 28|  Male|  Raghu|8501082222|    12|\n",
      "| 13|  Male|Murugan|8522209563|    16|\n",
      "| 31|  Male| Mukesh|8597638421|    17|\n",
      "+---+------+-------+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from users_json\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+----------+------+\n",
      "|age|gender|  name|     phone|userid|\n",
      "+---+------+------+----------+------+\n",
      "| 28|Female|Sandra|8508899001|     4|\n",
      "| 15|Female|Keerti|      null|     5|\n",
      "| 55|Female|Smriti|9246655498|     8|\n",
      "| 36|Female| Veena|8508888888|     9|\n",
      "| 15|Female| Kriti|      null|    10|\n",
      "| 55|Female| Ramya|9246654658|    13|\n",
      "| 31|Female|Hasina|8345213235|    14|\n",
      "| 37|Female| Lasya|      null|    15|\n",
      "+---+------+------+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3 = df1.where(\"gender = 'Female'\")\n",
    "df3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.write.parquet(\"E:\\\\PySpark\\\\output\\\\parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.read.parquet(\"E:\\\\PySpark\\\\output\\\\parquet\") \\\n",
    ".write \\\n",
    ".format(\"json\") \\\n",
    ".mode(\"append\") \\\n",
    ".saveAsTable(\"users_json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+-------+----------+------+\n",
      "|age|gender|   name|     phone|userid|\n",
      "+---+------+-------+----------+------+\n",
      "| 25|  Male|  Satya|8501099876|     1|\n",
      "| 25|  Male|  Rahim|      null|     3|\n",
      "| 13|  Male| Sundar|8522233456|     6|\n",
      "| 28|  Male|  Steve|8501085009|     7|\n",
      "| 13|  Male| Samuel|8522235624|    11|\n",
      "| 28|  Male|  Raghu|8501082222|    12|\n",
      "| 13|  Male|Murugan|8522209563|    16|\n",
      "| 31|  Male| Mukesh|8597638421|    17|\n",
      "| 28|Female| Sandra|8508899001|     4|\n",
      "| 15|Female| Keerti|      null|     5|\n",
      "| 55|Female| Smriti|9246655498|     8|\n",
      "| 36|Female|  Veena|8508888888|     9|\n",
      "| 15|Female|  Kriti|      null|    10|\n",
      "| 55|Female|  Ramya|9246654658|    13|\n",
      "| 31|Female| Hasina|8345213235|    14|\n",
      "| 37|Female|  Lasya|      null|    15|\n",
      "+---+------+-------+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from users_json\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+-------+----------+------+\n",
      "|age|gender|   name|     phone|userid|\n",
      "+---+------+-------+----------+------+\n",
      "| 25|  Male|  Satya|8501099876|     1|\n",
      "| 25|  Male|  Rahim|      null|     3|\n",
      "| 13|  Male| Sundar|8522233456|     6|\n",
      "| 28|  Male|  Steve|8501085009|     7|\n",
      "| 13|  Male| Samuel|8522235624|    11|\n",
      "| 28|  Male|  Raghu|8501082222|    12|\n",
      "| 13|  Male|Murugan|8522209563|    16|\n",
      "| 31|  Male| Mukesh|8597638421|    17|\n",
      "+---+------+-------+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read.parquet(\"E:\\\\PySpark\\\\external\\\\users_parquet\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Partitioned Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------+-------+----------+------+\n",
      "| age|gender|   name|     phone|userid|\n",
      "+----+------+-------+----------+------+\n",
      "|  25|  Male|  Satya|8501099876|     1|\n",
      "|null|  Male|   null|5676599876|     2|\n",
      "|  25|  Male|  Rahim|      null|     3|\n",
      "|  28|Female| Sandra|8508899001|     4|\n",
      "|  15|Female| Keerti|      null|     5|\n",
      "|  13|  Male| Sundar|8522233456|     6|\n",
      "|  28|  Male|  Steve|8501085009|     7|\n",
      "|  55|Female| Smriti|9246655498|     8|\n",
      "|  36|Female|  Veena|8508888888|     9|\n",
      "|  15|Female|  Kriti|      null|    10|\n",
      "|  13|  Male| Samuel|8522235624|    11|\n",
      "|  28|  Male|  Raghu|8501082222|    12|\n",
      "|  55|Female|  Ramya|9246654658|    13|\n",
      "|  31|Female| Hasina|8345213235|    14|\n",
      "|  37|Female|  Lasya|      null|    15|\n",
      "|  13|  Male|Murugan|8522209563|    16|\n",
      "|  31|  Male| Mukesh|8597638421|    17|\n",
      "+----+------+-------+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.write.format(\"csv\").option(\"header\", True).partitionBy(\"gender\").saveAsTable(\"users_partitioned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+----------+------+------+\n",
      "| age|   name|     phone|userid|gender|\n",
      "+----+-------+----------+------+------+\n",
      "|  25|  Satya|8501099876|     1|  Male|\n",
      "|null|   null|5676599876|     2|  Male|\n",
      "|  25|  Rahim|      null|     3|  Male|\n",
      "|  13| Sundar|8522233456|     6|  Male|\n",
      "|  28|  Steve|8501085009|     7|  Male|\n",
      "|  13| Samuel|8522235624|    11|  Male|\n",
      "|  28|  Raghu|8501082222|    12|  Male|\n",
      "|  13|Murugan|8522209563|    16|  Male|\n",
      "|  31| Mukesh|8597638421|    17|  Male|\n",
      "+----+-------+----------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from users_partitioned where gender = 'Male'\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+----------+------+------+\n",
      "| age|   name|     phone|userid|gender|\n",
      "+----+-------+----------+------+------+\n",
      "|  25|  Satya|8501099876|     1|  Male|\n",
      "|null|   null|5676599876|     2|  Male|\n",
      "|  25|  Rahim|      null|     3|  Male|\n",
      "|  13| Sundar|8522233456|     6|  Male|\n",
      "|  28|  Steve|8501085009|     7|  Male|\n",
      "|  13| Samuel|8522235624|    11|  Male|\n",
      "|  28|  Raghu|8501082222|    12|  Male|\n",
      "|  13|Murugan|8522209563|    16|  Male|\n",
      "|  31| Mukesh|8597638421|    17|  Male|\n",
      "+----+-------+----------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df4 = spark.sql(\"select * from users_partitioned where gender = 'Male'\")\n",
    "df4.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
